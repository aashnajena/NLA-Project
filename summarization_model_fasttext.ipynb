{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "summarization_model_fasttext.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/Summarization/blob/master/summarization_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe_SA3n0I3T8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import spacy\n",
        "import nltk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPRegressor as mlp\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb1g4I5ARGTp",
        "colab_type": "code",
        "outputId": "f47ceed3-437b-4e7e-86d4-e4fddb3f1352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UKpe_KPRLrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change to path to dataset\n",
        "file_name = \"/content/drive/My Drive/NLA project/fasttext.pkl\"\n",
        "stories = pickle.load(open(file_name, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEsDrJHUTOxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# basic embeddings using averaged glove vectors\n",
        "# using Spacy's large language model\n",
        "def get_embedding(text):\n",
        "    extract = embedder(text)\n",
        "    total_sum = np.zeros(300)\n",
        "    count = 0\n",
        "    for token in extract:\n",
        "        count += 1\n",
        "        total_sum += np.asarray(token.vector)\n",
        "    return total_sum / count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NkNVHrRGg_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_document_embedding(data):\n",
        "  total_sum = np.zeros(300)\n",
        "  for vector in data[\"fasttext_emb\"]:\n",
        "    total_sum += np.asarray(vector)\n",
        "  return total_sum/len(data[\"fasttext_emb\"])  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26X4T5jHRLpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating the inputs and expected outputs\n",
        "X_train = []\n",
        "y_train = []\n",
        "count = 0\n",
        "for data in stories:\n",
        "    count += 1\n",
        "    doc_emb = get_document_embedding(data)\n",
        "    # use the function of choice to generate the document embedding\n",
        "\n",
        "    index = 0\n",
        "    for sentence in data['fasttext_emb']:\n",
        "        sent_emb = sentence\n",
        "        # use the function of choice to generate the sentence embedding\n",
        "\n",
        "        x = np.concatenate((sent_emb, doc_emb))\n",
        "        y = data['scores'][index] \n",
        "        index += 1\n",
        "\n",
        "        X_train.append(x)\n",
        "        y_train.append(y)\n",
        "\n",
        "    if count > 100:\n",
        "        break\n",
        "\n",
        "X_train = np.asmatrix(X_train)\n",
        "y_train = np.asarray(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY6JkXtWWOwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(X, y):\n",
        "    model = mlp(hidden_layer_sizes = (1024, 2048, 1024, 512, 256), max_iter = 100)\n",
        "    model.fit(X, y)\n",
        "    return model\n",
        "\n",
        "def get_values(X, model):\n",
        "    return model.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZzWH2VWaQjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = train(X_train, 1000 * y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RHf3u63j1vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'fasttext_model.sav'\n",
        "pickle.dump(m, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl4yFkiyiTa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameter for similarity threshold\n",
        "theta = 0.95\n",
        "\n",
        "def similarity(A, B):\n",
        "    similarity =  (A @ B.T) / (np.linalg.norm(A) * np.linalg.norm(B))\n",
        "    return similarity\n",
        "\n",
        "def get_top_num(X_doc, y,num):\n",
        "    order = np.flip(np.argsort(y))\n",
        "    sentence_set = []\n",
        "    for sent_id in order:\n",
        "        if sentence_set == []:\n",
        "            sentence_set.append(order[0])\n",
        "            continue\n",
        "\n",
        "        consider = X_doc[sent_id, :]\n",
        "        flag = 1\n",
        "        for consider_id in sentence_set:\n",
        "            if similarity(X_doc[consider_id, :], consider) > theta:\n",
        "                flag = 0\n",
        "                break\n",
        "\n",
        "        if flag == 1:\n",
        "            sentence_set.append(sent_id)\n",
        "    return sentence_set[0: min(num, len(sentence_set))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph6OFgGwcewS",
        "colab_type": "code",
        "outputId": "628b07fe-ac18-4f54-b408-e4b189eea580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "# evaluation\n",
        "# testing out each document iteratively\n",
        "# test set: document 950 onwards\n",
        "\n",
        "doc_id = 980\n",
        "doc_count = len(stories)\n",
        "\n",
        "# set the number of documents for testing\n",
        "limit = 990\n",
        "\n",
        "while doc_id < min(doc_count, limit):\n",
        "    X_doc = []\n",
        "    y_doc = []\n",
        "    data = stories[doc_id]\n",
        "    doc_emb = get_document_embedding(data)\n",
        "\n",
        "    index = 0\n",
        "    for sentence in data['fasttext_emb']:\n",
        "        sent_emb = sentence\n",
        "\n",
        "        x = np.concatenate((sent_emb, doc_emb))\n",
        "        y = data['scores'][index] \n",
        "\n",
        "        index += 1\n",
        "\n",
        "        X_doc.append(x)\n",
        "        y_doc.append(y)\n",
        "\n",
        "    X_doc = np.asmatrix(X_doc)\n",
        "    y_doc = np.asarray(y_doc)\n",
        "\n",
        "    sentence_predicted_scores = get_values(X_doc, m)\n",
        "\n",
        "    loss = np.linalg.norm(sentence_predicted_scores - y_doc)\n",
        "\n",
        "    # Uncomment to view the test_loss on the sample  \n",
        "    # print(loss)\n",
        "\n",
        "    print(\"Document ID:\", doc_id, \", Top 5 Sentences:\", get_top_num(X_doc, sentence_predicted_scores,3))\n",
        "\n",
        "    # Uncomment to view the top 10 sentences based on Gold Labels\n",
        "    print(\"Top 10 sentences based on Gold Label\", np.flip(np.argsort(y_doc))[0:10])\n",
        "    doc_id += 1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Document ID: 980 , Top 5 Sentences: [7, 3, 4, 11, 1]\n",
            "Top 10 sentences based on Gold Label [12 11  1  0  5  2 14  4  6  7]\n",
            "Document ID: 981 , Top 5 Sentences: [49, 48, 37, 12, 33]\n",
            "Top 10 sentences based on Gold Label [ 2 25 14 17 31 13 22 21 20 19]\n",
            "Document ID: 982 , Top 5 Sentences: [3, 9, 11, 2, 13]\n",
            "Top 10 sentences based on Gold Label [ 7  1 19  4 11  0 16 12 17 20]\n",
            "Document ID: 983 , Top 5 Sentences: [10, 3, 9, 7, 5]\n",
            "Top 10 sentences based on Gold Label [ 9  4 10  1  7  0 13 12 11  8]\n",
            "Document ID: 984 , Top 5 Sentences: [51, 38, 46, 50, 47]\n",
            "Top 10 sentences based on Gold Label [ 1 54 57  0 53  2 27 13  3 16]\n",
            "Document ID: 985 , Top 5 Sentences: [3, 13, 4, 6, 10]\n",
            "Top 10 sentences based on Gold Label [ 6  0 15 14 13 12 11 10  9  8]\n",
            "Document ID: 986 , Top 5 Sentences: [8, 14, 15, 13, 1]\n",
            "Top 10 sentences based on Gold Label [ 0  1  2  4 12  9  3  5 15 14]\n",
            "Document ID: 987 , Top 5 Sentences: [3, 34, 32, 37, 23]\n",
            "Top 10 sentences based on Gold Label [15  0  2 26  8  5 11 17 16 14]\n",
            "Document ID: 988 , Top 5 Sentences: [3, 2, 0, 6, 5]\n",
            "Top 10 sentences based on Gold Label [1 7 6 5 4 3 2 0]\n",
            "Document ID: 989 , Top 5 Sentences: [7, 1, 6, 11, 15]\n",
            "Top 10 sentences based on Gold Label [11  4  2 10 18  7  1  3  5  6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uZR5MRhhD9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ^_^ Thank You"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fB-_jepnkNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model = pickle.load(open('fasttext_model.sav', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNbHRyd6nmP8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "164468df-d166-454c-a5b8-5f9d8c289e46"
      },
      "source": [
        "!pip install rouge"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azz-3WTCHQvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from rouge import Rouge "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67-MIN2BHUwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"/content/drive/My Drive/NLA project/sent2.pkl\"\n",
        "\n",
        "original_summaries = pickle.load(open(file_name, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCssNQqDHVLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gold_summaries = []\n",
        "for data in original_summaries:\n",
        "  summary = \" \".join(data[\"highlights\"])\n",
        "  gold_summaries.append(summary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkuPFP7LHXE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "3eb8f197-c987-4195-dfed-f9c2e709d3c3"
      },
      "source": [
        "gold_summaries[0]"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"haleh esfandiari says she read, walked, wrote a book in her mind while in prison scholar arrived home thursday after iran forbade her to leave for eight months iranian government never said why they released esfandiari from jail last month wilson center: ayatollah's letter marked first-ever response to american leader\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_9oRxD4HYv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_summaries = []\n",
        "exclude = []\n",
        "\n",
        "doc_id = 0\n",
        "doc_count = len(stories)\n",
        "\n",
        "limit = doc_count\n",
        "\n",
        "while doc_id < min(doc_count, limit):\n",
        "    try:\n",
        "      X_doc = []\n",
        "      y_doc = []\n",
        "      data = stories[doc_id]\n",
        "      doc_emb = get_document_embedding(data)\n",
        "\n",
        "      index = 0\n",
        "      for sentence in data[\"fasttext_emb\"]:\n",
        "          sent_emb = sentence\n",
        "\n",
        "          x = np.concatenate((sent_emb, doc_emb))\n",
        "          y = data['scores'][index] \n",
        "\n",
        "          index += 1\n",
        "\n",
        "          X_doc.append(x)\n",
        "          y_doc.append(y)\n",
        "\n",
        "      X_doc = np.asmatrix(X_doc)\n",
        "      y_doc = np.asarray(y_doc)\n",
        "\n",
        "      sentence_predicted_scores = get_values(X_doc, loaded_model)\n",
        "\n",
        "      loss = np.linalg.norm(sentence_predicted_scores - y_doc)\n",
        "\n",
        "      # Uncomment to view the test_loss on the sample  \n",
        "      # print(loss)\n",
        "\n",
        "      ids = get_top_num(X_doc, sentence_predicted_scores,4)\n",
        "      summary = ''\n",
        "      for idx in ids:\n",
        "        summary += original_summaries[doc_id]['story'][idx]\n",
        "      predicted_summaries.append(summary) \n",
        "    except:\n",
        "      exclude.append(doc_id)\n",
        "\n",
        "    doc_id+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVOlu3fLHcgf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "17502f90-fe01-41b8-8e1e-871856ee794e"
      },
      "source": [
        "exclude"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[269, 691]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvxyJfghI_IF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ind in exclude:\n",
        "  del gold_summaries[ind]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2ZJwcyRJCFy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e2a544ac-b7b1-4deb-ce61-14df84e8d4c3"
      },
      "source": [
        "print(len(gold_summaries),len(predicted_summaries))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "998 998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTUW0YKCJjlm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rouge = Rouge()\n",
        "scores = []\n",
        "for i in range(0,len(gold_summaries)):\n",
        "  scores.append(rouge.get_scores(predicted_summaries[i], gold_summaries[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9yvgY24JyQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "d22aa3bf-ce6d-49ca-9bba-f2aa3c2ddb0b"
      },
      "source": [
        "scores[0][0]"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge-1': {'f': 0.2087912048061829, 'p': 0.14393939393939395, 'r': 0.38},\n",
              " 'rouge-2': {'f': 0.05555555159321016,\n",
              "  'p': 0.03816793893129771,\n",
              "  'r': 0.10204081632653061},\n",
              " 'rouge-l': {'f': 0.17391303903381655,\n",
              "  'p': 0.13043478260869565,\n",
              "  'r': 0.2608695652173913}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5LW3m2hMMC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "average_rouge = {\n",
        "    'rouge_1':{'f' : 0, 'p' : 0, 'r' : 0},\n",
        "    'rouge_2':{'f' : 0, 'p' : 0, 'r' : 0},\n",
        "    'rouge_l':{'f' : 0, 'p' : 0, 'r' : 0},\n",
        "}\n",
        "for sc in scores:\n",
        "  score = sc[0]\n",
        "  average_rouge['rouge_1']['f'] += score['rouge-1']['f']\n",
        "  average_rouge['rouge_1']['p'] += score['rouge-1']['p']\n",
        "  average_rouge['rouge_1']['r'] += score['rouge-1']['r']\n",
        "  average_rouge['rouge_2']['f'] += score['rouge-2']['f']\n",
        "  average_rouge['rouge_2']['p'] += score['rouge-2']['p']\n",
        "  average_rouge['rouge_2']['r'] += score['rouge-2']['r']\n",
        "  average_rouge['rouge_l']['f'] += score['rouge-l']['f']\n",
        "  average_rouge['rouge_l']['p'] += score['rouge-l']['p']\n",
        "  average_rouge['rouge_l']['r'] += score['rouge-l']['r']\n",
        "\n",
        "average_rouge['rouge_1']['f'] /= len(scores)\n",
        "average_rouge['rouge_1']['p'] /= len(scores)\n",
        "average_rouge['rouge_1']['r'] /= len(scores)\n",
        "average_rouge['rouge_2']['f'] /= len(scores)\n",
        "average_rouge['rouge_2']['p'] /= len(scores)\n",
        "average_rouge['rouge_2']['r'] /= len(scores)\n",
        "average_rouge['rouge_l']['f'] /= len(scores)\n",
        "average_rouge['rouge_l']['p'] /= len(scores)\n",
        "average_rouge['rouge_l']['r'] /= len(scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPrkw7dPTjFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "24656b92-b662-45e7-ae0e-e79ad2acc25c"
      },
      "source": [
        "print(\"for top 3 sentences\")\n",
        "for key,value in average_rouge.items():\n",
        "  print(key)\n",
        "  for metric, val in value.items():\n",
        "    print(metric+\"\\t\"+str(val)) \n",
        "  print(\"--------------------------\")  "
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for top 3 sentences\n",
            "rouge_1\n",
            "f\t0.147817491063985\n",
            "p\t0.1191565027549791\n",
            "r\t0.21764581086768142\n",
            "--------------------------\n",
            "rouge_2\n",
            "f\t0.032386031740500275\n",
            "p\t0.025221901049095097\n",
            "r\t0.048653199042364106\n",
            "--------------------------\n",
            "rouge_l\n",
            "f\t0.12486465817585539\n",
            "p\t0.10309968285602499\n",
            "r\t0.17325227575193802\n",
            "--------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjUa2A4nVE7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "23c1d038-8a72-4ecd-d9dd-612671120677"
      },
      "source": [
        "print(\"for top 4 sentences\")\n",
        "for key,value in average_rouge.items():\n",
        "  print(key)\n",
        "  for metric, val in value.items():\n",
        "    print(metric+\"\\t\"+str(val)) \n",
        "  print(\"--------------------------\")  "
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for top 4 sentences\n",
            "rouge_1\n",
            "f\t0.23079145635431822\n",
            "p\t0.16910484132552217\n",
            "r\t0.407750460829676\n",
            "--------------------------\n",
            "rouge_2\n",
            "f\t0.07574577683375168\n",
            "p\t0.05437105405999294\n",
            "r\t0.1374281904099026\n",
            "--------------------------\n",
            "rouge_l\n",
            "f\t0.2050603948271745\n",
            "p\t0.15447521739850095\n",
            "r\t0.33267502866279164\n",
            "--------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTPEobDONj9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "c1f25a49-99b9-46e1-dbd0-6e78926c2290"
      },
      "source": [
        "print(\"for top 5 sentences\")\n",
        "for key,value in average_rouge.items():\n",
        "  print(key)\n",
        "  for metric, val in value.items():\n",
        "    print(metric+\"\\t\"+str(val)) \n",
        "  print(\"--------------------------\")  "
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for top 5 sentences\n",
            "rouge_1\n",
            "f\t0.22238089529088254\n",
            "p\t0.15288740384962163\n",
            "r\t0.45631344462363566\n",
            "--------------------------\n",
            "rouge_2\n",
            "f\t0.07475935402793302\n",
            "p\t0.05056098905490247\n",
            "r\t0.15767976167084463\n",
            "--------------------------\n",
            "rouge_l\n",
            "f\t0.2044236926545439\n",
            "p\t0.14525485867624255\n",
            "r\t0.3750272634696634\n",
            "--------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bce47frQOLxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}