{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "summarization_model_infersent_fasttext.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/Summarization/blob/master/summarization_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe_SA3n0I3T8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import spacy\n",
        "import nltk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPRegressor as mlp\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb1g4I5ARGTp",
        "colab_type": "code",
        "outputId": "0dd23274-8c7c-4913-a817-eea76d0cb229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UKpe_KPRLrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change to path to dataset\n",
        "\n",
        "## for fasttext embeddings use this\n",
        "#file_name = \"/content/drive/My Drive/NLA project/fasttext.pkl\"\n",
        "\n",
        "## for infersent embeddings use this\n",
        "file_name = \"/content/drive/My Drive/NLA project/infersent_emb.pkl\"\n",
        "\n",
        "stories = pickle.load(open(file_name, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEsDrJHUTOxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# basic embeddings using averaged glove vectors\n",
        "# using Spacy's large language model\n",
        "def get_embedding(text):\n",
        "    extract = embedder(text)\n",
        "    total_sum = np.zeros(300)\n",
        "    count = 0\n",
        "    for token in extract:\n",
        "        count += 1\n",
        "        total_sum += np.asarray(token.vector)\n",
        "    return total_sum / count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEw3LixGT6Az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMB = 'infersent'\n",
        "#EMB = 'fasttext_emb'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NkNVHrRGg_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_document_embedding(data):\n",
        "  ## for infersent use 4096, for fasttext and glove use 300\n",
        "  num_dimensions = 4096\n",
        "  total_sum = np.zeros(num_dimensions)\n",
        "  for vector in data[EMB]:\n",
        "    total_sum += np.asarray(vector)\n",
        "  return total_sum/len(data[EMB])  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26X4T5jHRLpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating the inputs and expected outputs\n",
        "X_train = []\n",
        "y_train = []\n",
        "count = 0\n",
        "for data in stories:\n",
        "    count += 1\n",
        "    doc_emb = get_document_embedding(data)\n",
        "    # use the function of choice to generate the document embedding\n",
        "\n",
        "    index = 0\n",
        "    for sentence in data[EMB]:\n",
        "        sent_emb = sentence\n",
        "        # use the function of choice to generate the sentence embedding\n",
        "\n",
        "        x = np.concatenate((sent_emb, doc_emb))\n",
        "        y = data['scores'][index] \n",
        "        index += 1\n",
        "\n",
        "        X_train.append(x)\n",
        "        y_train.append(y)\n",
        "\n",
        "    if count > 100:\n",
        "        break\n",
        "\n",
        "X_train = np.asmatrix(X_train)\n",
        "y_train = np.asarray(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY6JkXtWWOwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(X, y):\n",
        "    model = mlp(hidden_layer_sizes = (2048, 2048, 1024, 512, 256), max_iter = 100)\n",
        "    model.fit(X, y)\n",
        "    return model\n",
        "\n",
        "def get_values(X, model):\n",
        "    return model.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZzWH2VWaQjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = train(X_train, 1000 * y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ONtDlD5ey9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'infersent_model.sav'\n",
        "pickle.dump(m, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl4yFkiyiTa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameter for similarity threshold\n",
        "theta = 0.95\n",
        "\n",
        "def similarity(A, B):\n",
        "    similarity =  (A @ B.T) / (np.linalg.norm(A) * np.linalg.norm(B))\n",
        "    return similarity\n",
        "\n",
        "def get_top_num(X_doc, y, num):\n",
        "    order = np.flip(np.argsort(y))\n",
        "    sentence_set = []\n",
        "    for sent_id in order:\n",
        "        if sentence_set == []:\n",
        "            sentence_set.append(order[0])\n",
        "            continue\n",
        "\n",
        "        consider = X_doc[sent_id, :]\n",
        "        flag = 1\n",
        "        for consider_id in sentence_set:\n",
        "            if similarity(X_doc[consider_id, :], consider) > theta:\n",
        "                flag = 0\n",
        "                break\n",
        "\n",
        "        if flag == 1:\n",
        "            sentence_set.append(sent_id)\n",
        "    return sentence_set[0: min(num, len(sentence_set))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph6OFgGwcewS",
        "colab_type": "code",
        "outputId": "f1677ffc-9102-4c93-c36d-13f1e781583c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "# evaluation\n",
        "# testing out each document iteratively\n",
        "# test set: document 950 onwards\n",
        "\n",
        "doc_id = 955\n",
        "doc_count = len(stories)\n",
        "\n",
        "# set the number of documents for testing\n",
        "limit = 965\n",
        "\n",
        "while doc_id < min(doc_count, limit):\n",
        "    X_doc = []\n",
        "    y_doc = []\n",
        "    data = stories[doc_id]\n",
        "    doc_emb = get_document_embedding(data)\n",
        "\n",
        "    index = 0\n",
        "    for sentence in data[EMB]:\n",
        "        sent_emb = sentence\n",
        "\n",
        "        x = np.concatenate((sent_emb, doc_emb))\n",
        "        y = data['scores'][index] \n",
        "\n",
        "        index += 1\n",
        "\n",
        "        X_doc.append(x)\n",
        "        y_doc.append(y)\n",
        "\n",
        "    X_doc = np.asmatrix(X_doc)\n",
        "    y_doc = np.asarray(y_doc)\n",
        "\n",
        "    sentence_predicted_scores = get_values(X_doc, m)\n",
        "\n",
        "    loss = np.linalg.norm(sentence_predicted_scores - y_doc)\n",
        "\n",
        "    # Uncomment to view the test_loss on the sample  \n",
        "    # print(loss)\n",
        "\n",
        "    print(\"Document ID:\", doc_id, \", Top 5 Sentences:\", get_top_num(X_doc, sentence_predicted_scores,5))\n",
        "\n",
        "    # Uncomment to view the top 10 sentences based on Gold Labels\n",
        "    print(\"Top 10 sentences based on Gold Label\", np.flip(np.argsort(y_doc))[0:10])\n",
        "    doc_id += 1"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Document ID: 955 , Top 5 Sentences: [6, 3, 2, 11, 10]\n",
            "Top 10 sentences based on Gold Label [ 1 13  0  5 12  3 14 11 10  9]\n",
            "Document ID: 956 , Top 5 Sentences: [4, 0, 1, 7, 5]\n",
            "Top 10 sentences based on Gold Label [1 0 6 4 3 5 7 2]\n",
            "Document ID: 957 , Top 5 Sentences: [3, 2, 8, 12, 26]\n",
            "Top 10 sentences based on Gold Label [ 3 18 26  4 23  2  0 22  6 19]\n",
            "Document ID: 958 , Top 5 Sentences: [0, 6, 4, 9, 8]\n",
            "Top 10 sentences based on Gold Label [0 8 9 7 1 4 6 5 3 2]\n",
            "Document ID: 959 , Top 5 Sentences: [7, 3, 1, 6, 0]\n",
            "Top 10 sentences based on Gold Label [4 1 6 2 5 7 3 0]\n",
            "Document ID: 960 , Top 5 Sentences: [9, 8, 14, 7, 12]\n",
            "Top 10 sentences based on Gold Label [ 1  2  9 17  7 10  0  8 16 11]\n",
            "Document ID: 961 , Top 5 Sentences: [2, 0, 5, 3, 1]\n",
            "Top 10 sentences based on Gold Label [2 0 5 3 4 1]\n",
            "Document ID: 962 , Top 5 Sentences: [5, 0, 4, 2, 3]\n",
            "Top 10 sentences based on Gold Label [2 3 7 0 8 6 5 4 1]\n",
            "Document ID: 963 , Top 5 Sentences: [21, 35, 33, 28, 5]\n",
            "Top 10 sentences based on Gold Label [14 20  1  0 31 13 22 21 19 18]\n",
            "Document ID: 964 , Top 5 Sentences: [0, 3, 15, 10, 1]\n",
            "Top 10 sentences based on Gold Label [ 1  5 10  7  6 12  0 15  2  3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uZR5MRhhD9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ^_^ Thank You"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xzMRQDOiWG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model = pickle.load(open('infersent_model.sav', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZacDkOUiW-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "b9a49fab-c3c9-46e3-fb18-2497a5ad8a0f"
      },
      "source": [
        "doc_id = 955\n",
        "doc_count = len(stories)\n",
        "\n",
        "# set the number of documents for testing\n",
        "limit = 965\n",
        "\n",
        "while doc_id < min(doc_count, limit):\n",
        "    X_doc = []\n",
        "    y_doc = []\n",
        "    data = stories[doc_id]\n",
        "    doc_emb = get_document_embedding(data)\n",
        "\n",
        "    index = 0\n",
        "    for sentence in data[EMB]:\n",
        "        sent_emb = sentence\n",
        "\n",
        "        x = np.concatenate((sent_emb, doc_emb))\n",
        "        y = data['scores'][index] \n",
        "\n",
        "        index += 1\n",
        "\n",
        "        X_doc.append(x)\n",
        "        y_doc.append(y)\n",
        "\n",
        "    X_doc = np.asmatrix(X_doc)\n",
        "    y_doc = np.asarray(y_doc)\n",
        "\n",
        "    sentence_predicted_scores = get_values(X_doc, loaded_model)\n",
        "\n",
        "    loss = np.linalg.norm(sentence_predicted_scores - y_doc)\n",
        "\n",
        "    # Uncomment to view the test_loss on the sample  \n",
        "    # print(loss)\n",
        "\n",
        "    print(\"Document ID:\", doc_id, \", Top 5 Sentences:\", get_top_num(X_doc, sentence_predicted_scores,3))\n",
        "\n",
        "    # Uncomment to view the top 10 sentences based on Gold Labels\n",
        "    print(\"Top 10 sentences based on Gold Label\", np.flip(np.argsort(y_doc))[0:10])\n",
        "    doc_id += 1"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Document ID: 955 , Top 5 Sentences: [6, 3, 2]\n",
            "Top 10 sentences based on Gold Label [ 1 13  0  5 12  3 14 11 10  9]\n",
            "Document ID: 956 , Top 5 Sentences: [4, 0, 1]\n",
            "Top 10 sentences based on Gold Label [1 0 6 4 3 5 7 2]\n",
            "Document ID: 957 , Top 5 Sentences: [3, 2, 8]\n",
            "Top 10 sentences based on Gold Label [ 3 18 26  4 23  2  0 22  6 19]\n",
            "Document ID: 958 , Top 5 Sentences: [0, 6, 4]\n",
            "Top 10 sentences based on Gold Label [0 8 9 7 1 4 6 5 3 2]\n",
            "Document ID: 959 , Top 5 Sentences: [7, 3, 1]\n",
            "Top 10 sentences based on Gold Label [4 1 6 2 5 7 3 0]\n",
            "Document ID: 960 , Top 5 Sentences: [9, 8, 14]\n",
            "Top 10 sentences based on Gold Label [ 1  2  9 17  7 10  0  8 16 11]\n",
            "Document ID: 961 , Top 5 Sentences: [2, 0, 5]\n",
            "Top 10 sentences based on Gold Label [2 0 5 3 4 1]\n",
            "Document ID: 962 , Top 5 Sentences: [5, 0, 4]\n",
            "Top 10 sentences based on Gold Label [2 3 7 0 8 6 5 4 1]\n",
            "Document ID: 963 , Top 5 Sentences: [21, 35, 33]\n",
            "Top 10 sentences based on Gold Label [14 20  1  0 31 13 22 21 19 18]\n",
            "Document ID: 964 , Top 5 Sentences: [0, 3, 15]\n",
            "Top 10 sentences based on Gold Label [ 1  5 10  7  6 12  0 15  2  3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqh1va4HijHZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "6eace448-cb9d-4fd2-9672-6491ada1d826"
      },
      "source": [
        "!pip install rouge"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge) (1.12.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xg46DfgAEXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from rouge import Rouge "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwn5jR7VALTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"/content/drive/My Drive/NLA project/sent2.pkl\"\n",
        "\n",
        "original_summaries = pickle.load(open(file_name, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCOzlF5nQBSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1cd60202-51b4-46d2-c5d1-98a662008b29"
      },
      "source": [
        "av = 0\n",
        "for data in original_summaries:\n",
        "  av+=len(data[\"highlights\"])\n",
        "print(av/1000) "
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj12FGcGEacN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gold_summaries = []\n",
        "for data in original_summaries:\n",
        "  summary = \" \".join(data[\"highlights\"])\n",
        "  gold_summaries.append(summary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPZS71wbEfzA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "a4bfd2ef-b29b-4609-8f3e-26b1b840a771"
      },
      "source": [
        "gold_summaries[0]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"haleh esfandiari says she read, walked, wrote a book in her mind while in prison scholar arrived home thursday after iran forbade her to leave for eight months iranian government never said why they released esfandiari from jail last month wilson center: ayatollah's letter marked first-ever response to american leader\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePUvpQaZE5_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_summaries = []\n",
        "exclude = []\n",
        "\n",
        "doc_id = 0\n",
        "doc_count = len(stories)\n",
        "\n",
        "limit = doc_count\n",
        "\n",
        "while doc_id < min(doc_count, limit):\n",
        "    try:\n",
        "      X_doc = []\n",
        "      y_doc = []\n",
        "      data = stories[doc_id]\n",
        "      doc_emb = get_document_embedding(data)\n",
        "\n",
        "      index = 0\n",
        "      for sentence in data[EMB]:\n",
        "          sent_emb = sentence\n",
        "\n",
        "          x = np.concatenate((sent_emb, doc_emb))\n",
        "          y = data['scores'][index] \n",
        "\n",
        "          index += 1\n",
        "\n",
        "          X_doc.append(x)\n",
        "          y_doc.append(y)\n",
        "\n",
        "      X_doc = np.asmatrix(X_doc)\n",
        "      y_doc = np.asarray(y_doc)\n",
        "\n",
        "      sentence_predicted_scores = get_values(X_doc, loaded_model)\n",
        "\n",
        "      loss = np.linalg.norm(sentence_predicted_scores - y_doc)\n",
        "\n",
        "      # Uncomment to view the test_loss on the sample  \n",
        "      # print(loss)\n",
        "\n",
        "      ids = get_top_num(X_doc, sentence_predicted_scores,4)\n",
        "      summary = ''\n",
        "      for idx in ids:\n",
        "        summary += original_summaries[doc_id]['story'][idx]\n",
        "      predicted_summaries.append(summary)  \n",
        "    except:\n",
        "      exclude.append(doc_id)\n",
        "    doc_id+=1\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab6hH8LSFC8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ind in exclude:\n",
        "  del gold_summaries[ind]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUwr2-HSPKsn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8ac0a675-07f1-4da2-b299-257bb2449492"
      },
      "source": [
        "print(len(gold_summaries),len(predicted_summaries))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "998 998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xOi6yI2POgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rouge = Rouge()\n",
        "scores = []\n",
        "for i in range(0,len(gold_summaries)):\n",
        "  scores.append(rouge.get_scores(predicted_summaries[i], gold_summaries[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnbbSSkLPVvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "average_rouge = {\n",
        "    'rouge_1':{'f' : 0, 'p' : 0, 'r' : 0},\n",
        "    'rouge_2':{'f' : 0, 'p' : 0, 'r' : 0},\n",
        "    'rouge_l':{'f' : 0, 'p' : 0, 'r' : 0},\n",
        "}\n",
        "for sc in scores:\n",
        "  score = sc[0]\n",
        "  average_rouge['rouge_1']['f'] += score['rouge-1']['f']\n",
        "  average_rouge['rouge_1']['p'] += score['rouge-1']['p']\n",
        "  average_rouge['rouge_1']['r'] += score['rouge-1']['r']\n",
        "  average_rouge['rouge_2']['f'] += score['rouge-2']['f']\n",
        "  average_rouge['rouge_2']['p'] += score['rouge-2']['p']\n",
        "  average_rouge['rouge_2']['r'] += score['rouge-2']['r']\n",
        "  average_rouge['rouge_l']['f'] += score['rouge-l']['f']\n",
        "  average_rouge['rouge_l']['p'] += score['rouge-l']['p']\n",
        "  average_rouge['rouge_l']['r'] += score['rouge-l']['r']\n",
        "\n",
        "average_rouge['rouge_1']['f'] /= len(scores)\n",
        "average_rouge['rouge_1']['p'] /= len(scores)\n",
        "average_rouge['rouge_1']['r'] /= len(scores)\n",
        "average_rouge['rouge_2']['f'] /= len(scores)\n",
        "average_rouge['rouge_2']['p'] /= len(scores)\n",
        "average_rouge['rouge_2']['r'] /= len(scores)\n",
        "average_rouge['rouge_l']['f'] /= len(scores)\n",
        "average_rouge['rouge_l']['p'] /= len(scores)\n",
        "average_rouge['rouge_l']['r'] /= len(scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCr5I1jSPl97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "0ddeb1d2-602d-4050-eca3-5f1f2c07be48"
      },
      "source": [
        "print(\"For top five sentences\")\n",
        "for key,value in average_rouge.items():\n",
        "  print(key)\n",
        "  for metric, val in value.items():\n",
        "    print(metric+\"\\t\"+str(val)) \n",
        "  print(\"--------------------------\") "
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For top five sentences\n",
            "rouge_1\n",
            "f\t0.21218549949989918\n",
            "p\t0.13743780821078694\n",
            "r\t0.514433460338619\n",
            "--------------------------\n",
            "rouge_2\n",
            "f\t0.07780463190895977\n",
            "p\t0.05039379155868287\n",
            "r\t0.18894813470729832\n",
            "--------------------------\n",
            "rouge_l\n",
            "f\t0.20578917643633968\n",
            "p\t0.13901717381078943\n",
            "r\t0.427076310748189\n",
            "--------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4ew0U0AV9N_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "66fb7599-4e0e-4791-8de4-b80b5c58ab35"
      },
      "source": [
        "print(\"For top four sentences\")\n",
        "for key,value in average_rouge.items():\n",
        "  print(key)\n",
        "  for metric, val in value.items():\n",
        "    print(metric+\"\\t\"+str(val)) \n",
        "  print(\"--------------------------\") "
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For top four sentences\n",
            "rouge_1\n",
            "f\t0.2263082742007271\n",
            "p\t0.15504706773578525\n",
            "r\t0.4615344756485788\n",
            "--------------------------\n",
            "rouge_2\n",
            "f\t0.07889476867782748\n",
            "p\t0.05397341665789107\n",
            "r\t0.16101318569672227\n",
            "--------------------------\n",
            "rouge_l\n",
            "f\t0.2087232440138955\n",
            "p\t0.14863005286219036\n",
            "r\t0.3777621191330641\n",
            "--------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-PcOqHCPqkR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "a34a35e3-ae6c-405f-dbf4-aadfbd6d46dc"
      },
      "source": [
        "print(\"For top three sentences\")\n",
        "for key,value in average_rouge.items():\n",
        "  print(key)\n",
        "  for metric, val in value.items():\n",
        "    print(metric+\"\\t\"+str(val)) \n",
        "  print(\"--------------------------\")"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For top three sentences\n",
            "rouge_1\n",
            "f\t0.23837762616307634\n",
            "p\t0.17870970342922088\n",
            "r\t0.3948210652772677\n",
            "--------------------------\n",
            "rouge_2\n",
            "f\t0.0782952265255066\n",
            "p\t0.0586625199432189\n",
            "r\t0.1290943302874871\n",
            "--------------------------\n",
            "rouge_l\n",
            "f\t0.20978198592978672\n",
            "p\t0.16219584658887584\n",
            "r\t0.32059361189593455\n",
            "--------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2N2ZeTCTx_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}